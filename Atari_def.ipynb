{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sid27/miniconda3/envs/atari_sl/lib/python3.10/site-packages/ray/air/_internal/remote_storage.py:4: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  from pkg_resources import packaging\n",
      "/home/sid27/miniconda3/envs/atari_sl/lib/python3.10/site-packages/ray/tune/logger/tensorboardx.py:35: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  VALID_NP_HPARAMS = (np.bool8, np.float32, np.float64, np.int32, np.int64)\n",
      "A.L.E: Arcade Learning Environment (version 0.7.4+069f8bd)\n",
      "[Powered by Stella]\n",
      "/home/sid27/miniconda3/envs/atari_sl/lib/python3.10/site-packages/gym/utils/seeding.py:138: DeprecationWarning: \u001b[33mWARN: Function `hash_seed(seed, max_bytes)` is marked as deprecated and will be removed in the future. \u001b[0m\n",
      "  deprecation(\n",
      "/home/sid27/miniconda3/envs/atari_sl/lib/python3.10/site-packages/gym/utils/seeding.py:175: DeprecationWarning: \u001b[33mWARN: Function `_bigint_from_bytes(bytes)` is marked as deprecated and will be removed in the future. \u001b[0m\n",
      "  deprecation(\n",
      "2024-01-05 00:29:44,842\tWARNING deprecation.py:47 -- DeprecationWarning: `FrameStack` has been deprecated. This will raise an error in the future!\n",
      "loss=0.3788: 100%|██████████| 938/938 [1:58:08<00:00,  7.56s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, val_loss=0.3044, val_acc=89.00%\n",
      "Mean return 3.7 (n=10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.2148: 100%|██████████| 938/938 [1:47:47<00:00,  6.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, val_loss=0.2708, val_acc=90.44%\n",
      "Mean return 10.8 (n=10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.1808:   5%|▌         | 50/938 [05:54<2:04:02,  8.38s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mUntitled-2.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:Untitled-2.ipynb?jupyter-notebook#W0sdW50aXRsZWQ%3D?line=158'>159</a>\u001b[0m optimizer \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m0.0001\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell:Untitled-2.ipynb?jupyter-notebook#W0sdW50aXRsZWQ%3D?line=160'>161</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m50\u001b[39m):  \u001b[39m# loop over the dataset multiple times\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell:Untitled-2.ipynb?jupyter-notebook#W0sdW50aXRsZWQ%3D?line=161'>162</a>\u001b[0m     train_one_epoch(model, criterion, optimizer, trainloader)\n\u001b[1;32m    <a href='vscode-notebook-cell:Untitled-2.ipynb?jupyter-notebook#W0sdW50aXRsZWQ%3D?line=163'>164</a>\u001b[0m     \u001b[39m# Evaluate model on the validation set\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:Untitled-2.ipynb?jupyter-notebook#W0sdW50aXRsZWQ%3D?line=164'>165</a>\u001b[0m     val_loss, val_acc \u001b[39m=\u001b[39m \u001b[39meval\u001b[39m(model, valloader)\n",
      "\u001b[1;32mUntitled-2.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:Untitled-2.ipynb?jupyter-notebook#W0sdW50aXRsZWQ%3D?line=100'>101</a>\u001b[0m outputs \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m*\u001b[39moutputs\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m:])  \u001b[39m# flatten\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:Untitled-2.ipynb?jupyter-notebook#W0sdW50aXRsZWQ%3D?line=101'>102</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m--> <a href='vscode-notebook-cell:Untitled-2.ipynb?jupyter-notebook#W0sdW50aXRsZWQ%3D?line=102'>103</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m    <a href='vscode-notebook-cell:Untitled-2.ipynb?jupyter-notebook#W0sdW50aXRsZWQ%3D?line=103'>104</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m    <a href='vscode-notebook-cell:Untitled-2.ipynb?jupyter-notebook#W0sdW50aXRsZWQ%3D?line=105'>106</a>\u001b[0m \u001b[39m# print statistics\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/atari_sl/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    493\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    494\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/atari_sl/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m     tensors,\n\u001b[1;32m    253\u001b[0m     grad_tensors_,\n\u001b[1;32m    254\u001b[0m     retain_graph,\n\u001b[1;32m    255\u001b[0m     create_graph,\n\u001b[1;32m    256\u001b[0m     inputs,\n\u001b[1;32m    257\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    258\u001b[0m     accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    259\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Copyright 2022 Mathias Lechner\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import gym\n",
    "import ale_py\n",
    "import torch\n",
    "from ray.rllib.env.wrappers.atari_wrappers import wrap_deepmind\n",
    "from torch.utils.data import Dataset\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "from ncps.torch import CfC\n",
    "from ncps.datasets.torch import AtariCloningDataset\n",
    "\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(4, 64, 5, padding=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(64, 128, 5, padding=2, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.conv3 = nn.Conv2d(128, 128, 5, padding=2, stride=2)\n",
    "        self.conv4 = nn.Conv2d(128, 256, 5, padding=2, stride=2)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = x.mean((-1, -2))  # Global average pooling\n",
    "        return x\n",
    "\n",
    "\n",
    "class ConvCfC(nn.Module):\n",
    "    def __init__(self, n_actions):\n",
    "        super().__init__()\n",
    "        self.conv_block = ConvBlock()\n",
    "        self.rnn = CfC(256, 64, batch_first=True, proj_size=n_actions)\n",
    "\n",
    "    def forward(self, x, hx=None):\n",
    "        batch_size = x.size(0)\n",
    "        seq_len = x.size(1)\n",
    "        # Merge time and batch dimension into a single one (because the Conv layers require this)\n",
    "        x = x.view(batch_size * seq_len, *x.shape[2:])\n",
    "        x = self.conv_block(x)  # apply conv block to merged data\n",
    "        # Separate time and batch dimension again\n",
    "        x = x.view(batch_size, seq_len, *x.shape[1:])\n",
    "        x, hx = self.rnn(x, hx)  # hx is the hidden state of the RNN\n",
    "        return x, hx\n",
    "\n",
    "\n",
    "def eval(model, valloader):\n",
    "    losses, accs = [], []\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device  # get device the model is located on\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in valloader:\n",
    "            inputs = inputs.to(device)  # move data to same device as the model\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs, _ = model(inputs)\n",
    "            outputs = outputs.reshape(-1, *outputs.shape[2:])  # flatten\n",
    "            labels = labels.view(-1, *labels.shape[2:])  # flatten\n",
    "            loss = criterion(outputs, labels)\n",
    "            acc = (outputs.argmax(-1) == labels).float().mean()\n",
    "            losses.append(loss.item())\n",
    "            accs.append(acc.item())\n",
    "    return np.mean(losses), np.mean(accs)\n",
    "\n",
    "\n",
    "def train_one_epoch(model, criterion, optimizer, trainloader):\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(total=len(trainloader))\n",
    "    model.train()\n",
    "    device = next(model.parameters()).device  # get device the model is located on\n",
    "    for i, (inputs, labels) in enumerate(trainloader):\n",
    "        inputs = inputs.to(device)  # move data to same device as the model\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        outputs, hx = model(inputs)\n",
    "        labels = labels.view(-1, *labels.shape[2:])  # flatten\n",
    "        outputs = outputs.reshape(-1, *outputs.shape[2:])  # flatten\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        pbar.set_description(f\"loss={running_loss / (i + 1):0.4g}\")\n",
    "        pbar.update(1)\n",
    "    pbar.close()\n",
    "\n",
    "\n",
    "def run_closed_loop(model, env, num_episodes=None):\n",
    "    obs = env.reset()\n",
    "    device = next(model.parameters()).device\n",
    "    hx = None  # Hidden state of the RNN\n",
    "    returns = []\n",
    "    total_reward = 0\n",
    "    with torch.no_grad():\n",
    "        while True:\n",
    "            # PyTorch require channel first images -> transpose data\n",
    "            obs = np.transpose(obs, [2, 0, 1]).astype(np.float32)\n",
    "            # Observation seems to be already normalized, see: https://github.com/mlech26l/ncps/issues/48#issuecomment-1572328370\n",
    "            # obs = np.transpose(obs, [2, 0, 1]).astype(np.float32) / 255.0\n",
    "            # add batch and time dimension (with a single element in each)\n",
    "            obs = torch.from_numpy(obs).unsqueeze(0).unsqueeze(0).to(device)\n",
    "            pred, hx = model(obs, hx)\n",
    "            # remove time and batch dimension -> then argmax\n",
    "            action = pred.squeeze(0).squeeze(0).argmax().item()\n",
    "            obs, r, done, _ = env.step(action)\n",
    "            total_reward += r\n",
    "            if done:\n",
    "                obs = env.reset()\n",
    "                hx = None  # Reset hidden state of the RNN\n",
    "                returns.append(total_reward)\n",
    "                total_reward = 0\n",
    "                if num_episodes is not None:\n",
    "                    # Count down the number of episodes\n",
    "                    num_episodes = num_episodes - 1\n",
    "                    if num_episodes == 0:\n",
    "                        return returns\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    env = gym.make(\"ALE/Breakout-v5\")\n",
    "    # We need to wrap the environment with the Deepmind helper functions\n",
    "    env = wrap_deepmind(env)\n",
    "\n",
    "    train_ds = AtariCloningDataset(\"breakout\", split=\"train\")\n",
    "    val_ds = AtariCloningDataset(\"breakout\", split=\"val\")\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        train_ds, batch_size=32, num_workers=4, shuffle=True\n",
    "    )\n",
    "    valloader = torch.utils.data.DataLoader(val_ds, batch_size=32, num_workers=4)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = ConvCfC(n_actions=env.action_space.n).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "    for epoch in range(50):  # loop over the dataset multiple times\n",
    "        train_one_epoch(model, criterion, optimizer, trainloader)\n",
    "\n",
    "        # Evaluate model on the validation set\n",
    "        val_loss, val_acc = eval(model, valloader)\n",
    "        print(f\"Epoch {epoch+1}, val_loss={val_loss:0.4g}, val_acc={100*val_acc:0.2f}%\")\n",
    "\n",
    "        # Apply model in closed-loop environment\n",
    "        returns = run_closed_loop(model, env, num_episodes=10)\n",
    "        print(f\"Mean return {np.mean(returns)} (n={len(returns)})\")\n",
    "\n",
    "    # Visualize Atari game and play endlessly\n",
    "    env = gym.make(\"ALE/Breakout-v5\", render_mode=\"human\")\n",
    "    env = wrap_deepmind(env)\n",
    "    run_closed_loop(model, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atari_sl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
